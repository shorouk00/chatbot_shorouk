# -*- coding: utf-8 -*-
from flask import Flask, request, jsonify, render_template
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
import gdown
import os
import requests
import zipfile
import shutil

app = Flask(__name__)

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¶Ù…ÙŠÙ† (Embedding Model) ---
print("Initializing embedding model...")
embedding_model = HuggingFaceEmbeddings(
    model_name="BAAI/bge-large-en-v1.5",
    model_kwargs={"device": "cpu"},
    encode_kwargs={"normalize_embeddings": True}
)
print("Embedding model initialized.")

# --- 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Chroma ---
# Ø¨ÙŠØ§Ù†Ø§Øª ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
zip_url = "https://drive.google.com/uc?id=1TRCTZ_txfmdzSfEGr_YXS9h4Kx4ZWNEx"
db_directory = "chroma_db"  # Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

# Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø¬Ù„Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø«Ù… Ù†Ù‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„Ù‡ ÙˆØ¥Ø¹Ø¯Ø§Ø¯Ù‡
if not os.path.isdir(db_directory):
    print(f"Database directory '{db_directory}' not found. Starting download and setup...")
    temp_zip_path = "chroma_dataset.zip"
    temp_extract_path = "chroma_dataset_temp"

    # Ø§Ù„Ø®Ø·ÙˆØ© Ø£: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
    try:
        print(f"Downloading data from Google Drive...")
        gdown.download(url=zip_url, output=temp_zip_path, quiet=False)
        print("Download complete.")
    except Exception as e:
        print(f"FATAL ERROR: Failed to download the file: {e}")
        exit()

    # Ø§Ù„Ø®Ø·ÙˆØ© Ø¨: ÙÙƒ Ø¶ØºØ· Ø§Ù„Ù…Ù„Ù
    try:
        print(f"Extracting '{temp_zip_path}' to temporary directory '{temp_extract_path}'...")
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø¤Ù‚Øª ÙØ§Ø±Øº ÙˆÙ†Ø¸ÙŠÙ
        if os.path.exists(temp_extract_path):
            shutil.rmtree(temp_extract_path)
        os.makedirs(temp_extract_path)

        with zipfile.ZipFile(temp_zip_path, 'r') as zip_ref:
            zip_ref.extractall(temp_extract_path)
        print("Extraction complete.")
        # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¶ØºÙˆØ· Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù†Ù‡
        os.remove(temp_zip_path)
    except Exception as e:
        print(f"FATAL ERROR: Failed to extract the zip file: {e}")
        if os.path.exists(temp_zip_path):
            os.remove(temp_zip_path) # ØªÙ†Ø¸ÙŠÙ
        exit()

    # Ø§Ù„Ø®Ø·ÙˆØ© Ø¬: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµØ­ÙŠØ­ ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØªÙ‡
    try:
        extracted_contents = os.listdir(temp_extract_path)
        print(f"Contents of temporary directory: {extracted_contents}")

        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¶ØºÙˆØ· ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¬Ù„Ø¯ Ø±Ø¦ÙŠØ³ÙŠ ÙˆØ§Ø­Ø¯ Ø¨Ø¯Ø§Ø®Ù„Ù‡
        if len(extracted_contents) == 1 and os.path.isdir(os.path.join(temp_extract_path, extracted_contents[0])):
            source_path = os.path.join(temp_extract_path, extracted_contents[0])
            print(f"Detected nested directory: '{source_path}'. Moving it to '{db_directory}'.")
            shutil.move(source_path, db_directory)
            shutil.rmtree(temp_extract_path) # Ø­Ø°Ù Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø¤Ù‚Øª Ø§Ù„ÙØ§Ø±Øº
        else:
            # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ø¨Ø§Ø´Ø±Ø© ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯
            print(f"Data is directly in the root. Moving '{temp_extract_path}' to '{db_directory}'.")
            shutil.move(temp_extract_path, db_directory)

        print(f"Database successfully placed at '{db_directory}'.")
    except Exception as e:
        print(f"FATAL ERROR: Failed to organize the database directory: {e}")
        exit()
else:
    print(f"Database directory '{db_directory}' already exists. Skipping download.")

# --- 3. ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Chroma ---
try:
    print(f"Loading vector store from: '{db_directory}'...")
    # ØªØ­Ù‚Ù‚ Ø­Ø§Ø³Ù…: Ù‡Ù„ ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù€ ChromaØŸ
    if not os.path.exists(os.path.join(db_directory, "chroma.sqlite3")):
         raise FileNotFoundError(f"Chroma database file (chroma.sqlite3) not found in '{db_directory}'. The directory structure is incorrect or the download failed.")

    vector_store = Chroma(
        persist_directory=db_directory,
        embedding_function=embedding_model
    )
    print("Vector store loaded successfully.")
except Exception as e:
    print(f"CRITICAL ERROR: Failed to load the Chroma database. {e}")
    exit()

# --- 4. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ Retriever ---
retriever = vector_store.as_retriever(
    search_kwargs={"k": 5},
    search_type="mmr"
)
print("Retriever is ready.")

# --- 5. Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª (API) Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ ---
# Ø§Ù†ØªØ¨Ù‡: ÙŠØ¬Ø¨ Ø­Ù…Ø§ÙŠØ© Ù…ÙØªØ§Ø­ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬
HF_API_KEY = os.getenv("OPENROUTER_API_KEY", "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")

def call_llm_api(prompt: str):
    """Calls the OpenRouter API to get a response from the LLM."""
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {HF_API_KEY}",
    }
    payload = {
        "model": "deepseek/deepseek-chat-v3-0324:free", # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ¯ÙŠÙ„ Ù‚ÙŠØ§Ø³ÙŠ Ù„Ù„ØªÙˆØ§ÙÙ‚ÙŠØ©
        "messages": [{"role": "user", "content": prompt}],
    }
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        response.raise_for_status()  # This will raise an HTTPError for bad responses (4xx or 5xx)
        return response.json()["choices"][0]["message"]["content"]
    except requests.exceptions.RequestException as e:
        print(f"API Request Error: {e}")
        return f"Error communicating with the API: {e}"
    except (KeyError, IndexError) as e:
        print(f"API Response Parsing Error: {e}")
        return "Error parsing the response from the API."
    except Exception as e:
        print(f"An unexpected error occurred in call_llm_api: {e}")
        return "An unexpected error occurred."


# --- 6. Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ·Ø¨ÙŠÙ‚ Flask ---
@app.route('/')
def home():
    # ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù 'index.html' ÙÙŠ Ù…Ø¬Ù„Ø¯ 'templates'
    return render_template('index.html')

@app.route('/ask', methods=['POST'])
def ask():
    """Handles the incoming question from the user."""
    try:
        data = request.get_json()
        if not data or 'query' not in data:
            return jsonify({'error': 'Invalid request. "query" field is missing.'}), 400

        user_query = data['query']
        print(f"Received query: {user_query}")
        answer = ask_question(user_query)
        return jsonify({'answer': answer})
    except Exception as e:
        print(f"Error in /ask endpoint: {e}")
        return jsonify({'error': f'An internal server error occurred: {e}'}), 500

def ask_question(query: str) -> str:
    """Uses the RAG pipeline to answer a question."""
    # Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
    docs = retriever.invoke(query)
    context = "\n\n".join([doc.page_content for doc in docs]) if docs else "No relevant context found."
    print(f"Retrieved context for query '{query}':\n---\n{context}\n---")

    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ Prompt
    prompt = f"""You are an expert assistant. Your ONLY source of information is the provided "Context".
You MUST answer questions using ONLY the information explicitly given in the "Context".
If the question is a greeting (e.g., "hi", "hello", "hey", "greetings", "how are you"), reply with exactly: "Hello! How can I assist you today? ğŸ˜Š".
If the answer can be found directly or inferred clearly from the "Context", provide that answer concisely.
If the answer is NOT in the "Context" or cannot be directly inferred, you MUST reply with exactly: "Sorry, I don't have enough information about your question"
Do NOT add extra explanations, guesses, or unrelated information.

Context:
{context}

Question:
{query}
"""
    answer = call_llm_api(prompt)
    return answer

if __name__ == '__main__':
    # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† debug=False ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬
    app.run(debug=True, port=5000)
